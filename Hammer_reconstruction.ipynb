{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7059cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd21a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the most likely outcome (binary string)\n",
    "def predict_binary_string(predictions, num_qubits):\n",
    "    # Get the index of the maximum probability\n",
    "    max_index = torch.argmax(predictions).item()\n",
    "\n",
    "    # Convert index to corresponding binary string\n",
    "    result_string = bin(max_index)[2:].zfill(num_qubits)\n",
    "    return result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb71c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(predictions, ground_truth):\n",
    "    correct = 0\n",
    "    total = len(predictions)\n",
    "\n",
    "    for predicted, true in zip(predictions, ground_truth):\n",
    "        \n",
    "        # Compare the predicted binary string with the true label\n",
    "        if predicted == true:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c906cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(distribution, target=None, window=30):\n",
    "    distribution = np.array(distribution)\n",
    "    x = np.arange(len(distribution))\n",
    "\n",
    "    if target is not None and 0 <= target < len(distribution):\n",
    "        start = max(target - window // 2, 0)\n",
    "        end = min(target + window // 2 + 1, len(distribution))\n",
    "        x = x[start:end]\n",
    "        distribution = distribution[start:end]\n",
    "        colors = ['skyblue'] * len(distribution)\n",
    "        colors[target - start] = 'red'\n",
    "    else:\n",
    "        colors = ['skyblue'] * len(distribution)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.bar(x, distribution, color=colors)\n",
    "    plt.xlabel(\"Index\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.title(\"Zoomed Distribution Around Target\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f6be37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rank(data_dict, target):\n",
    "    # Convert dict items to a list of (bit_string, value) pairs\n",
    "    items = list(data_dict.items())\n",
    "    # Sort by value in descending order\n",
    "    sorted_items = sorted(items, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Create a mapping from bit string to rank (1-based)\n",
    "    rank_map = {bit: rank+1 for rank, (bit, _) in enumerate(sorted_items)}\n",
    "    \n",
    "    # Return the rank of the target bit string\n",
    "    return rank_map.get(target, None)  # Returns None if target not in dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d1c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fid_class(dist_a, dist_b):\n",
    "    \"\"\"\n",
    "    Calculate the fidelity between two probability distributions.\n",
    "\n",
    "    Args:\n",
    "        dist_a (list): The first probability distribution.\n",
    "        dist_b (list): The second probability distribution.\n",
    "\n",
    "    Returns:\n",
    "        float: The fidelity between the two distributions.\n",
    "    \"\"\"\n",
    "    fid = 0\n",
    "\n",
    "    for a, b in zip(dist_a, dist_b):\n",
    "        # Calculate the square root of the product of corresponding elements in the distributions\n",
    "        fid += np.sqrt(a * b)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b261f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newResultDict(test_case):\n",
    "    dict = {\"secret_string\":test_case}\n",
    "    stringArray = [\"0\"] * len(test_case)\n",
    "    string = \"\".join(stringArray)\n",
    "    while(True):\n",
    "        dict[string] = 0\n",
    "        if(string == \"1\" * len(test_case)):\n",
    "            break\n",
    "        for i in range(len(string)):\n",
    "            if string[i] == \"0\":\n",
    "                if string[i+1:].find(\"0\") == -1:\n",
    "                    stringArray[i] = \"1\"\n",
    "                    for v in range(i + 1, len(test_case)):\n",
    "                        stringArray[v] = \"0\"\n",
    "                    string = \"\".join(stringArray)\n",
    "                    break\n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2654a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamm_dist(x, y):\n",
    "    if(len(x) != len(y)):\n",
    "        return\n",
    "    count = 0\n",
    "    for i in range(len(x)):\n",
    "        if(x[i] != y[i]):\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a51a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hamm_Method(set):\n",
    "    length = math.floor(n/2)\n",
    "    CHS = [0.0] * length\n",
    "    for x in set.keys():\n",
    "        if x == \"secret_string\":\n",
    "            continue\n",
    "        for y in set.keys():\n",
    "            if y == \"secret_string\":\n",
    "                continue\n",
    "            d = hamm_dist(x, y)\n",
    "            if d < math.floor(n/2):\n",
    "                CHS[d] += float(set[y])\n",
    "    W = [0.0] * length\n",
    "    for i in range(length):\n",
    "        if CHS[i] > 0:\n",
    "            W[i] = 1/CHS[i]\n",
    "    result = newResultDict(set[\"secret_string\"])\n",
    "    for x in set.keys():\n",
    "        if x == \"secret_string\":\n",
    "            continue\n",
    "        score = float(set[x])\n",
    "        for y in set.keys():\n",
    "            if y == \"secret_string\":\n",
    "                continue\n",
    "            d = hamm_dist(x, y)\n",
    "            if d < math.floor(n/2) and float(set[x]) > float(set[y]):\n",
    "                score += W[d] * float(set[y])\n",
    "            result[x] = score * float(set[x])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1596c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(set):\n",
    "    total = 0\n",
    "    for x in set:\n",
    "        if x == \"secret_string\":\n",
    "            continue\n",
    "        total += float(set[x])\n",
    "    for x in set:\n",
    "        if x == \"secret_string\":\n",
    "            continue\n",
    "        set[x] = float(set[x])/total\n",
    "    return set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5054d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec_to_countsVec(decimal, n_qubits, n_shots):\n",
    "    res = [0] * (2**n_qubits)\n",
    "    res[decimal] = n_shots\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481a997d",
   "metadata": {},
   "source": [
    "Test Hammer code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352cec8b-15b5-4042-8f6e-a1568e4f03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 9 #set to length of strings in file\n",
    "key_list = []\n",
    "result_bank = []\n",
    "\n",
    "filename = f\"1_7-ones_9qubitsBV.csv\" #set to file name\n",
    "\n",
    "with open(filename, 'r', newline='') as csvfile:\n",
    "    resultDict = newResultDict(\"0\" * n)\n",
    "    reader = csv.DictReader(csvfile, fieldnames = resultDict.keys())\n",
    "    for row in reader:\n",
    "        key_list.append(row['secret_string'])\n",
    "        result_bank.append({k: int(v) for k, v in list(row.items())[1:]})\n",
    "\n",
    "data_dicts = []\n",
    "for i in range(len(key_list)):\n",
    "    temp = {}\n",
    "    temp[\"input\"] = result_bank[i]\n",
    "    temp[\"target\"] = key_list[i]\n",
    "    data_dicts.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d809f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dicts = data_dicts[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7d336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_list_b4 = []\n",
    "for i in range(len(data_dicts)):\n",
    "    rank_list_b4.append(get_rank(data_dicts[i][\"input\"], data_dicts[i][\"target\"]))\n",
    "rank_list_b4 = np.array(rank_list_b4)\n",
    "rank_list_b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f55ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in range(len(data_dicts)):\n",
    "    X.append([j for j in data_dicts[i]['input'].values()])\n",
    "    y.append(data_dicts[i]['target'])\n",
    "\n",
    "X = np.array(X)\n",
    "X = X / X.sum(axis=1, keepdims=True)  # Normalizing noisy counts to sum to 1\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "target_bits = copy.deepcopy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821376b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(X[1], int(y[1], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5b53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_predict = []\n",
    "for i in range(len(X_tensor)):\n",
    "    predicted_string = predict_binary_string(X_tensor[i], num_qubits=9)\n",
    "    original_predict.append(predicted_string)\n",
    "calculate_accuracy(original_predict, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a4848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y)):\n",
    "    y[i] = dec_to_countsVec(int(y[i],2), n, 10240)\n",
    "\n",
    "y = np.array(y)\n",
    "y = y / y.sum(axis=1, keepdims=True)  # Normalizing ideal counts to sum to 1\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5c3968",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = X_tensor.cpu().numpy()\n",
    "true = y_tensor.cpu().numpy()\n",
    "fidelities = [fid_class(p, t) for p, t in zip(pred, true)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd24c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fidelities = np.array(fidelities)\n",
    "average_fid = np.mean(fidelities)\n",
    "average_fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af42dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hammer_results = []\n",
    "with open(filename, 'r', newline='') as csvfile:\n",
    "    resultDict = newResultDict(\"0\" * n)\n",
    "    reader = csv.DictReader(csvfile, fieldnames = resultDict.keys())\n",
    "    for row in reader:\n",
    "        resultDict = newResultDict(\"0\" * n)\n",
    "        for key in resultDict.keys():\n",
    "            resultDict[key] = row[key]\n",
    "        resultDict = normalize(resultDict)\n",
    "        print(\"Before Hamming Method\")\n",
    "        rowAbbr = [(i, float(resultDict[i])) for i in resultDict.keys()] # in tuples to make it easier to sort\n",
    "        rowAbbr.sort(key = lambda pair:(-pair[1], pair[0])) #sorting by number of shots first, and string order second\n",
    "        origRank = 1\n",
    "        found = False\n",
    "        for i in rowAbbr[0:10]:\n",
    "            if i[0] == \"secret_string\":\n",
    "                print(i)\n",
    "            else:\n",
    "                print(\"    \", i) #indenting results to make it easier to tell where one test ends and another begins\n",
    "                if(not found):\n",
    "                    origRank += 1\n",
    "                    if(i[0] == resultDict[\"secret_string\"]):\n",
    "                        found = True\n",
    "        print(\"Rank:\", origRank)\n",
    "        #Hamming Method Time\n",
    "        resultDict = newResultDict(\"0\" * n)\n",
    "        for key in resultDict.keys():\n",
    "            resultDict[key] = row[key]\n",
    "        resultDict = Hamm_Method(resultDict)\n",
    "        resultDict = normalize(resultDict)\n",
    "        print(\"After Hamming Method\")\n",
    "        rowAbbr = [(i, float(resultDict[i])) for i in resultDict.keys()] # in tuples to make it easier to sort\n",
    "        rowAbbr.sort(key = lambda pair:(-pair[1], pair[0])) #sorting by number of shots first, and string order second\n",
    "        hamRank = 1\n",
    "        found = False\n",
    "        for i in rowAbbr[0:10]:\n",
    "            if i[0] == \"secret_string\":\n",
    "                print(i)\n",
    "            else:\n",
    "                print(\"    \", i) #indenting results to make it easier to tell where one test ends and another begins\n",
    "                if(not found):\n",
    "                    hamRank += 1\n",
    "                    if(i[0] == resultDict[\"secret_string\"]):\n",
    "                        found = True\n",
    "        print(\"Rank:\", hamRank)\n",
    "        print(\"                Rank Improvement:\", (hamRank - origRank))\n",
    "        #Second Pass?\n",
    "        resultDict = Hamm_Method(resultDict)\n",
    "        resultDict = normalize(resultDict)\n",
    "        print(\"After Hamming Method (2)\")\n",
    "        rowAbbr = [(i, float(resultDict[i])) for i in resultDict.keys()] # in tuples to make it easier to sort\n",
    "        rowAbbr.sort(key = lambda pair:(-pair[1], pair[0])) #sorting by number of shots first, and string order second\n",
    "        hamRank = 1\n",
    "        found = False\n",
    "        for i in rowAbbr[0:10]:\n",
    "            if i[0] == \"secret_string\":\n",
    "                print(i)\n",
    "            else:\n",
    "                print(\"    \", i) #indenting results to make it easier to tell where one test ends and another begins\n",
    "                if(not found):\n",
    "                    hamRank += 1\n",
    "                    if(i[0] == resultDict[\"secret_string\"]):\n",
    "                        found = True\n",
    "        print(\"Rank:\", hamRank)\n",
    "        print(\"                            Rank Improvement:\", (hamRank - origRank))\n",
    "        Hammer_results.append(resultDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba37ffd0-c5f5-4c4f-be69-9ad03897daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = copy.deepcopy(Hammer_results)\n",
    "data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e89eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hammer_data_dicts = []\n",
    "for i in data_copy:\n",
    "    temp = {}\n",
    "    temp['target'] = i['secret_string']\n",
    "    i.pop('secret_string')\n",
    "    temp['input'] = i\n",
    "    Hammer_data_dicts.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520cf160",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hammer_data_dicts = Hammer_data_dicts[::-1]\n",
    "Hammer_data_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f6cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in range(len(Hammer_data_dicts)):\n",
    "    X.append([j for j in Hammer_data_dicts[i]['input'].values()])\n",
    "    y.append(Hammer_data_dicts[i]['target'])\n",
    "\n",
    "X = np.array(X)\n",
    "X = X / X.sum(axis=1, keepdims=True)  # Normalizing noisy counts to sum to 1\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df5385",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(X[1], int(y[1], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05eb7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hammer_predict = []\n",
    "for i in range(len(X_tensor)):\n",
    "    predicted_string = predict_binary_string(X_tensor[i], num_qubits=9)\n",
    "    Hammer_predict.append(predicted_string)\n",
    "calculate_accuracy(Hammer_predict, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802d886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_list_after = []\n",
    "for i in range(len(Hammer_data_dicts)):\n",
    "    rank_list_after.append(get_rank(Hammer_data_dicts[i][\"input\"], Hammer_data_dicts[i][\"target\"]))\n",
    "rank_list_after = np.array(rank_list_after)\n",
    "rank_list_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531225fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "increase = 0\n",
    "decrease = 0\n",
    "for i in range(len(rank_list_b4)):\n",
    "    if rank_list_b4[i] < rank_list_after[i]:\n",
    "        decrease += 1\n",
    "    if rank_list_b4[i] > rank_list_after[i]:\n",
    "        increase += 1\n",
    "increase, decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8cce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y)):\n",
    "    y[i] = dec_to_countsVec(int(y[i],2), n, 10240)\n",
    "\n",
    "y = np.array(y)\n",
    "y = y / y.sum(axis=1, keepdims=True)  # Normalizing ideal counts to sum to 1\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0fe338",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = X_tensor.cpu().numpy()\n",
    "true = y_tensor.cpu().numpy()\n",
    "fidelities = [fid_class(p, t) for p, t in zip(pred, true)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7414b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fidelities = np.array(fidelities)\n",
    "average_fid = np.mean(fidelities)\n",
    "average_fid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qbeep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
